{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGCcObGJrOFGyAMb5Pr6HS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KashyapTimbadiya/CE146_ML_Labs/blob/main/ML_Lab08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stacking Algorithm Implementation**"
      ],
      "metadata": {
        "id": "wNB0jeHMKD5_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dmEVIQGGJ-zP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data (Breast Cancer Dataset)\n",
        "#holdout -> validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "data=load_breast_cancer()\n",
        "data_df = pd.DataFrame(data = data.data,\n",
        "                       columns = data.feature_names)\n",
        "\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(X, y, random_state=146, train_size=0.6)\n",
        "\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, random_state=146, test_size=0.3)\n",
        "\n",
        "print(X.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz2liCLXKCZT",
        "outputId": "29452a45-faa5-4e8d-cd95-65d9b54bf172"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# individual learners of the model\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "models = dict()\n",
        "# preds = list()\n",
        "models['lr'] = LogisticRegression(max_iter=100000)\n",
        "models['cart'] = DecisionTreeClassifier()\n",
        "models['bayes'] = GaussianNB()\n",
        "\n",
        "\n",
        "\n",
        "for model in models:\n",
        "  models[model].fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "sJgN8h15KKk6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataframe in which each column represents predicted values of predictors\n",
        "#Predicting output for holdout(validation) set\n",
        "\n",
        "# for model in models:\n",
        "pred1 = models['lr'].predict(X_valid)\n",
        "pred2 = models['cart'].predict(X_valid)\n",
        "pred3 = models['bayes'].predict(X_valid)\n",
        "\n",
        "test_preds1 = models['lr'].predict(X_test)\n",
        "test_preds2 = models['cart'].predict(X_test)\n",
        "test_preds3 = models['bayes'].predict(X_test)\n",
        "\n",
        "data_df_new = pd.DataFrame(data = X_valid,\n",
        "                       columns = data.feature_names)\n",
        "data_df_new['lr'] = pred1\n",
        "data_df_new['cart'] = pred2\n",
        "data_df_new['bayes'] = pred3\n",
        "\n",
        "\n",
        "print(data_df_new.info())\n",
        "print(data_df_new.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lec6we-XKMh8",
        "outputId": "7b5d1a2e-080c-4c97-df27-cac2c833c759"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159 entries, 0 to 158\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              159 non-null    float64\n",
            " 1   mean texture             159 non-null    float64\n",
            " 2   mean perimeter           159 non-null    float64\n",
            " 3   mean area                159 non-null    float64\n",
            " 4   mean smoothness          159 non-null    float64\n",
            " 5   mean compactness         159 non-null    float64\n",
            " 6   mean concavity           159 non-null    float64\n",
            " 7   mean concave points      159 non-null    float64\n",
            " 8   mean symmetry            159 non-null    float64\n",
            " 9   mean fractal dimension   159 non-null    float64\n",
            " 10  radius error             159 non-null    float64\n",
            " 11  texture error            159 non-null    float64\n",
            " 12  perimeter error          159 non-null    float64\n",
            " 13  area error               159 non-null    float64\n",
            " 14  smoothness error         159 non-null    float64\n",
            " 15  compactness error        159 non-null    float64\n",
            " 16  concavity error          159 non-null    float64\n",
            " 17  concave points error     159 non-null    float64\n",
            " 18  symmetry error           159 non-null    float64\n",
            " 19  fractal dimension error  159 non-null    float64\n",
            " 20  worst radius             159 non-null    float64\n",
            " 21  worst texture            159 non-null    float64\n",
            " 22  worst perimeter          159 non-null    float64\n",
            " 23  worst area               159 non-null    float64\n",
            " 24  worst smoothness         159 non-null    float64\n",
            " 25  worst compactness        159 non-null    float64\n",
            " 26  worst concavity          159 non-null    float64\n",
            " 27  worst concave points     159 non-null    float64\n",
            " 28  worst symmetry           159 non-null    float64\n",
            " 29  worst fractal dimension  159 non-null    float64\n",
            " 30  lr                       159 non-null    int64  \n",
            " 31  cart                     159 non-null    int64  \n",
            " 32  bayes                    159 non-null    int64  \n",
            "dtypes: float64(30), int64(3)\n",
            "memory usage: 41.1 KB\n",
            "None\n",
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        15.28         22.41           98.92      710.6          0.09057   \n",
            "1        10.90         12.96           68.69      366.8          0.07515   \n",
            "2        16.78         18.80          109.30      886.3          0.08865   \n",
            "3        13.17         21.81           85.42      531.5          0.09714   \n",
            "4        15.46         11.89          102.50      736.9          0.12570   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.10520         0.05375             0.032630         0.1727   \n",
            "1           0.03718         0.00309             0.006588         0.1442   \n",
            "2           0.09182         0.08422             0.065760         0.1893   \n",
            "3           0.10470         0.08259             0.052520         0.1746   \n",
            "4           0.15550         0.20320             0.109700         0.1966   \n",
            "\n",
            "   mean fractal dimension  ...  worst area  worst smoothness  \\\n",
            "0                 0.06317  ...       973.1            0.1301   \n",
            "1                 0.05743  ...       470.0            0.1171   \n",
            "2                 0.05534  ...      1260.0            0.1168   \n",
            "3                 0.06177  ...       740.7            0.1503   \n",
            "4                 0.07069  ...      1102.0            0.1531   \n",
            "\n",
            "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
            "0            0.32990          0.36300               0.12260          0.3175   \n",
            "1            0.08294          0.01854               0.03953          0.2738   \n",
            "2            0.21190          0.23180               0.14740          0.2810   \n",
            "3            0.39040          0.37280               0.16070          0.3693   \n",
            "4            0.35830          0.58300               0.18270          0.3216   \n",
            "\n",
            "   worst fractal dimension  lr  cart  bayes  \n",
            "0                  0.09772   0     0      1  \n",
            "1                  0.07685   1     1      1  \n",
            "2                  0.07228   0     0      0  \n",
            "3                  0.09618   0     0      1  \n",
            "4                  0.10100   0     0      0  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW9qZRjqKOGc",
        "outputId": "ba2dacbc-7dec-4beb-a0a3-3510f939d1dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
            "0        17.99         10.38          122.80     1001.0          0.11840   \n",
            "1        20.57         17.77          132.90     1326.0          0.08474   \n",
            "2        19.69         21.25          130.00     1203.0          0.10960   \n",
            "3        11.42         20.38           77.58      386.1          0.14250   \n",
            "4        20.29         14.34          135.10     1297.0          0.10030   \n",
            "\n",
            "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
            "0           0.27760          0.3001              0.14710         0.2419   \n",
            "1           0.07864          0.0869              0.07017         0.1812   \n",
            "2           0.15990          0.1974              0.12790         0.2069   \n",
            "3           0.28390          0.2414              0.10520         0.2597   \n",
            "4           0.13280          0.1980              0.10430         0.1809   \n",
            "\n",
            "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
            "0                 0.07871  ...         25.38          17.33           184.60   \n",
            "1                 0.05667  ...         24.99          23.41           158.80   \n",
            "2                 0.05999  ...         23.57          25.53           152.50   \n",
            "3                 0.09744  ...         14.91          26.50            98.87   \n",
            "4                 0.05883  ...         22.54          16.67           152.20   \n",
            "\n",
            "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
            "0      2019.0            0.1622             0.6656           0.7119   \n",
            "1      1956.0            0.1238             0.1866           0.2416   \n",
            "2      1709.0            0.1444             0.4245           0.4504   \n",
            "3       567.7            0.2098             0.8663           0.6869   \n",
            "4      1575.0            0.1374             0.2050           0.4000   \n",
            "\n",
            "   worst concave points  worst symmetry  worst fractal dimension  \n",
            "0                0.2654          0.4601                  0.11890  \n",
            "1                0.1860          0.2750                  0.08902  \n",
            "2                0.2430          0.3613                  0.08758  \n",
            "3                0.2575          0.6638                  0.17300  \n",
            "4                0.1625          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_stack = np.column_stack((pred1,pred2,pred3))\n",
        "test_stack = np.column_stack((test_preds1,test_preds2,test_preds3))"
      ],
      "metadata": {
        "id": "KcVlr60KKRt0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#blender\n",
        "final_model = LogisticRegression(max_iter=100000)\n",
        "\n",
        "final_model.fit(train_stack,y_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DMJN11IKSYf",
        "outputId": "95b97e58-bbe6-4e13-da4e-2fc796c23121"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=100000)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions = final_model.predict(test_stack)"
      ],
      "metadata": {
        "id": "iZiVi0vDKTuI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check accuracy on Test Set\n",
        "#Show classification report\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "print(\"Accuracy: \",metrics.accuracy_score(y_test, final_predictions))\n",
        "print(\"Precision: \",metrics.precision_score(y_test, final_predictions))\n",
        "print(\"Recall: \",metrics.recall_score(y_test, final_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg-QtWOZKVAX",
        "outputId": "022a18cc-a1f2-4602-a703-dcd216ee2a24"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9130434782608695\n",
            "Precision:  0.8863636363636364\n",
            "Recall:  0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def model_Evaluate(model, y_test, final_predictions):\n",
        "# Predict values for Test dataset\n",
        "  # y_pred = model.predict(X_test)\n",
        "  # Print the evaluation metrics for the dataset.\n",
        "  print(classification_report(y_test, final_predictions))\n",
        "  # Compute and plot the Confusion matrix\n",
        "  # cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "  # categories = ['Negative','Positive']\n",
        "  # group_names = ['True Neg','False Pos', 'False Neg','True Pos']\n",
        "  # group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
        "  # labels = [f'{v1}n{v2}' for v1, v2 in zip(group_names,group_percentages)]\n",
        "  # labels = np.asarray(labels).reshape(2,2)\n",
        "  # sns.heatmap(cf_matrix, annot = labels, cmap = 'Blues',fmt = '',\n",
        "  # xticklabels = categories, yticklabels = categories)\n",
        "  # plt.xlabel(\"Predicted values\", fontdict = {'size':14}, labelpad = 10)\n",
        "  # plt.ylabel(\"Actual values\" , fontdict = {'size':14}, labelpad = 10)\n",
        "  # plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)\n",
        "\n",
        "model_Evaluate(final_model, y_test, final_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_s9cRVJKWk6",
        "outputId": "990cdfdb-9392-4fc4-c9fb-d78a35e4923d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.83      0.89        29\n",
            "           1       0.89      0.97      0.93        40\n",
            "\n",
            "    accuracy                           0.91        69\n",
            "   macro avg       0.92      0.90      0.91        69\n",
            "weighted avg       0.92      0.91      0.91        69\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **StackingClassifier from sklearn**\n",
        "Use StackingClassifier from sklearn to implement the same on cancer dataset.\n",
        "Bagging and RandomForest"
      ],
      "metadata": {
        "id": "y4pJvq4-KdqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "data=load_breast_cancer()\n",
        "data_df = pd.DataFrame(data = data.data,\n",
        "                       columns = data.feature_names)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=146, train_size=0.8)\n",
        "\n",
        "\n",
        "model1 = LogisticRegression(max_iter=100000)\n",
        "model2 = DecisionTreeClassifier()\n",
        "model3 = GaussianNB()\n",
        "\n",
        "print(y_test)\n",
        "# X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, random_state=97, test_size=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrdGLmf3Ki0Y",
        "outputId": "fff24700-c965-4acb-a8b9-87f78778859a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0\n",
            " 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1\n",
            " 1 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1\n",
            " 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [\n",
        "     ('lr', model1),\n",
        "     ('cart', model2),\n",
        "     ('bayes', model3)\n",
        "]\n",
        "\n",
        "final_model = LogisticRegression(max_iter=100000)\n",
        "sclf = StackingClassifier(estimators=estimators,\n",
        "                            final_estimator=final_model,\n",
        "                            cv=10)\n",
        "\n"
      ],
      "metadata": {
        "id": "Pp1zZGAoKjnu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit Bagging Classifier on Cancer Dataset\n",
        "\n",
        "sclf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS_5Rob4KmF7",
        "outputId": "0d0d2e78-984a-4816-b2c0-40952be5bf53"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingClassifier(cv=10,\n",
              "                   estimators=[('lr', LogisticRegression(max_iter=100000)),\n",
              "                               ('cart', DecisionTreeClassifier()),\n",
              "                               ('bayes', GaussianNB())],\n",
              "                   final_estimator=LogisticRegression(max_iter=100000))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = sclf.predict(X_test)"
      ],
      "metadata": {
        "id": "LvU9tzDWKojf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: \",sclf.score(X_test, y_test))\n",
        "print(\"Precision: \",metrics.precision_score( y_test, prediction))\n",
        "print(\"Accuracy: \",metrics.recall_score( y_test, prediction))\n",
        "\n",
        "# model_Evaluate(sclf, y_test, prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2bZ9cSRLKqL",
        "outputId": "20c8d306-75ff-46b8-ae84-fad5a976673f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9649122807017544\n",
            "Precision:  0.9459459459459459\n",
            "Accuracy:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adaboost**"
      ],
      "metadata": {
        "id": "HzBYZEsnLMil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "data=load_breast_cancer()\n",
        "data_df = pd.DataFrame(data = data.data,\n",
        "                       columns = data.feature_names)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=146, train_size=0.8)\n",
        "\n",
        "\n",
        "model1 = LogisticRegression(max_iter=100000)\n",
        "model2 = DecisionTreeClassifier()\n",
        "model3 = GaussianNB()\n",
        "\n",
        "estimators = [\n",
        "     ('lr', model1),\n",
        "     ('cart', model2),\n",
        "     ('bayes', model3)\n",
        "]"
      ],
      "metadata": {
        "id": "tfwUWJZVLLOP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abc = AdaBoostClassifier(learning_rate=1)\n",
        "abc.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8K3CL0OLRli",
        "outputId": "ef12334c-a569-4ea3-f824-0d68299e1735"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(learning_rate=1)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = abc.predict(X_test)"
      ],
      "metadata": {
        "id": "w0j3fZ6iLTAd"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(\"Accuracy: \",abc.score(X_test, y_test))\n",
        "print(\"Precision: \",metrics.precision_score(y_test, prediction))\n",
        "print(\"Recall: \",metrics.recall_score( y_test, prediction))\n",
        "\n",
        "# model_Evaluate(abc, y_test, prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5kkB71HLUdF",
        "outputId": "7df93092-d3f9-49a9-f120-2ef9c09cecb6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9649122807017544\n",
            "Precision:  0.9714285714285714\n",
            "Recall:  0.9714285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adaboost Regression on concrete_data.csv.**"
      ],
      "metadata": {
        "id": "vuamXasaLXD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "datasets = pd.read_csv('/content/drive/MyDrive/ML_Labs/Contrete.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B2ziQ-bLXpa",
        "outputId": "99b784ee-7d91-4118-fc26-001d8bbe0de6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = datasets.iloc[:, :-1].values\n",
        "\n",
        "# Only last column, 0 for 1st column and -1 for last colum,-2 for 2nd last column\n",
        "y = datasets.iloc[:, -1].values\n",
        "print(\"\\n\\nInput : \\n\", X)\n",
        "print(\"\\n\\nOutput: \\n\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "garVFuHULblQ",
        "outputId": "27e600ee-4026-4ff5-e401-f15e0d3ee112"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Input : \n",
            " [[ 540.     0.     0.  ... 1040.   676.    28. ]\n",
            " [ 540.     0.     0.  ... 1055.   676.    28. ]\n",
            " [ 332.5  142.5    0.  ...  932.   594.   270. ]\n",
            " ...\n",
            " [ 148.5  139.4  108.6 ...  892.4  780.    28. ]\n",
            " [ 159.1  186.7    0.  ...  989.6  788.9   28. ]\n",
            " [ 260.9  100.5   78.3 ...  864.5  761.5   28. ]]\n",
            "\n",
            "\n",
            "Output: \n",
            " [79.99 61.89 40.27 ... 23.7  32.77 32.4 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#split data set into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(datasets, y, test_size = 0.25, random_state = 146)\n",
        "\n",
        "# print(y_test)"
      ],
      "metadata": {
        "id": "7DqFeg_gLdHn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        " \n",
        "#Choosing Decision Tree with 1 level as the weak learner\n",
        "DTR=DecisionTreeRegressor(max_depth=1)\n",
        "RegModel = AdaBoostRegressor(n_estimators=50, base_estimator=DTR ,learning_rate=1)"
      ],
      "metadata": {
        "id": "1QiPJT12LeS2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the model on Training Data\n",
        "AB=RegModel.fit(X_train,y_train)\n",
        "y_pred=AB.predict(X_test)\n",
        "\n",
        "# print(predictions)"
      ],
      "metadata": {
        "id": "F64WMlAxLfzC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "# model_Evaluate(AB, y_test, predictions) --> doesn't work for continuous values\n",
        "print(\"Accuracy: \",RegModel.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BctJnunILg_E",
        "outputId": "88d1d54b-7cea-49e7-e540-27a7f13ce4b5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.754772117560399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X,y = load_diabetes(return_X_y=True)\n",
        "\n",
        "#split data set into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 146)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        " \n",
        "#Choosing Decision Tree with 1 level as the weak learner\n",
        "DTR=DecisionTreeRegressor(max_depth=10)\n",
        "RegModel = AdaBoostRegressor(n_estimators=100, base_estimator=DTR ,learning_rate=1)\n",
        "\n",
        "AB=RegModel.fit(X_train,y_train)\n",
        "y_pred=AB.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# model_Evaluate(AB, y_test, predictions) --> doesn't work for continuous values\n",
        "print(\"Accuracy: \",RegModel.score(X_test, y_test))\n",
        "\n",
        "print(\"Mean Square Error: \",mean_squared_error(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c2VseZILiNG",
        "outputId": "f04dd7e7-f5f1-40fb-b732-d27179bbef58"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.36678891520304624\n",
            "Mean Square Error:  3673.369659850946\n"
          ]
        }
      ]
    }
  ]
}